import time
import json
import pandas as pd
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup
from webdriver_manager.chrome import ChromeDriverManager

def fetch_race_with_selenium(race_id):
    """netkeiba å‡ºé¦¬è¡¨ãƒšãƒ¼ã‚¸ã‹ã‚‰ __NEXT_DATA__ ã‚’Seleniumã§æŠ½å‡º"""
    url = f"https://race.netkeiba.com/race/shutuba.html?race_id={race_id}"
    print(f"ğŸ“˜ ã‚¢ã‚¯ã‚»ã‚¹ä¸­: {url}")

    options = Options()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")

    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
    driver.get(url)
    time.sleep(4)  # JSæç”»å¾…ã¡

    soup = BeautifulSoup(driver.page_source, "html.parser")
    driver.quit()

    script_tag = soup.find("script", id="__NEXT_DATA__")
    if not script_tag:
        print("âŒ __NEXT_DATA__ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return pd.DataFrame()

    data = json.loads(script_tag.string)
    try:
        horses = data["props"]["pageProps"]["race"]["horses"]
    except KeyError:
        print("âš ï¸ horsesãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ§‹é€ ãŒå¤‰ã‚ã£ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        return pd.DataFrame()

    df = pd.DataFrame(horses)
    df.to_csv("data/syutubahyo_auto.csv", index=False, encoding="utf-8-sig")
    print(f"âœ… å‡ºé¦¬è¡¨ã‚’å–å¾—ã—ã¾ã—ãŸï¼ˆ{len(df)}é ­ï¼‰")
    return df


if __name__ == "__main__":
    race_id = input("å–å¾—ã—ãŸã„ãƒ¬ãƒ¼ã‚¹IDã‚’å…¥åŠ›ï¼ˆä¾‹ï¼š202405040811ï¼‰: ").strip()
    fetch_race_with_selenium(race_id)
